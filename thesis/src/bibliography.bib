%
% This is file `coppe.bib'.
%
% Bibliographic references for the documentation.
%
% Copyright (C) 2011 CoppeTeX Project and any individual authors listed
% elsewhere in this file.
%
% This program is free software; you can redistribute it and/or modify
% it under the terms of the GNU General Public License version 3 as
% published by the Free Software Foundation.
%
% This program is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
% GNU General Public License version 3 for more details.
%
% You should have received a copy of the GNU General Public License
% version 3 along with this package (see COPYING file).
% If not, see <http://www.gnu.org/licenses/>.
%
% $URL: https://coppetex.svn.sourceforge.net/svnroot/coppetex/trunk/coppe.bib $
% $Id: coppe.bib 118 2008-10-18 14:17:06Z helano $
%
% Author(s): Vicente H. F. Batista
%            George O. Ainsworth Jr.
%


@inproceedings{detecting_change_in_data_streams,
    author = {Kifer, Daniel and Ben-David, Shai and Gehrke, Johannes},
    title = {Detecting Change in Data Streams},
    booktitle = {Proceedings of the Thirtieth International Conference on Very Large Data Bases - Volume 30},
    series = {VLDB '04},
    year = {2004},
    isbn = {0-12-088469-0},
    location = {Toronto, Canada},
    pages = {180--191},
    numpages = {12},
    url = {http://dl.acm.org/citation.cfm?id=1316689.1316707},
    acmid = {1316707},
    publisher = {VLDB Endowment},
}

@article{optimal_detection_of_changepoints_with_a_linear_computational_cost,
  title={Optimal detection of changepoints with a linear computational cost},
  author={Killick, Rebecca and Fearnhead, Paul and Eckley, IA},
  journal={Journal of the American Statistical Association},
  volume={107},
  number={500},
  pages={1590--1598},
  year={2012},
  publisher={Taylor \& Francis}
}

@article{on_optimal_multiple_changepoint_algorithms_for_large_data,
  title={On optimal multiple changepoint algorithms for large data},
  author={Maidstone, Robert and Hocking, Toby and Rigaill, Guillem and Fearnhead, Paul},
  journal={Statistics and Computing},
  pages={1--15},
  year={2016},
  publisher={Springer US}
}

@Article{algorithms_for_the_optimal_identification_of_segment_neighborhoods,
author="Auger, Ivan E.
and Lawrence, Charles E.",
title="Algorithms for the optimal identification of segment neighborhoods",
journal="Bulletin of Mathematical Biology",
year="1989",
volume="51",
number="1",
pages="39--54",
abstract="Two algorithms for the efficient identification of segment neighborhoods are presented. A segment neighborhood is a set of contiguous residues that share common features. Two procedures are developed to efficiently find estimates for the parameters of the model that describe these features and for the residues that define the boundaries of each segment neighborhood. The algorithms can accept nearly any model of segment neighborhood, and can be applied with a broad class of best fit functions including least squares and maximum likelihood. The algorithms successively identify the most important features of the sequence. The application of one of these methods to the haemagglutinin protein of influenza virus reveals a possible mechanism for conformational change through the finding of a break in a strong heptad repeat structure.",
issn="1522-9602",
doi="10.1007/BF02458835",
url="http://dx.doi.org/10.1007/BF02458835"
}

@article{computationally_efficient_changepoint_detection_for_a_range_of_penalties,
author = {Kaylea Haynes and Idris A. Eckley and Paul Fearnhead},
title = {Computationally Efficient Changepoint Detection for a Range of Penalties},
journal = {Journal of Computational and Graphical Statistics},
volume = {0},
number = {ja},
pages = {1-28},
year = {0},
doi = {10.1080/10618600.2015.1116445},

URL = { 
        http://dx.doi.org/10.1080/10618600.2015.1116445
    
},
eprint = { 
        http://dx.doi.org/10.1080/10618600.2015.1116445
    
}
,
    abstract = { In the multiple changepoint setting, various search methods have been proposed which involve optimising either a constrained or penalised cost function over possible numbers and locations of changepoints using dynamic programming. Recent work in the penalised optimisation setting has focussed on developing an exact pruning-based approach which, under certain conditions, is linear in the number of data points. Such an approach naturally requires the specification of a penalty to avoid under/over-fitting. Work has been undertaken to identify the appropriate penalty choice for data generating processes with known distributional form, but in many applications the model assumed for the data is not correct and these penalty choices are not always appropriate. To this end we present a method that enables us to find the solution path for all choice of penalty values across a continuous range. This permits an evaluation of the various segmentations to identify a suitable penalty choice. The computational complexity of this approach can be linear in the number of data points and linear in the difference between the number of changepoints in the optimal segmentations for the smallest and largest penalty values. }
}

@Article{a_hidden_markov_model_segmentation_procedure_for_hydrological_and_environmental_time_series,
author="Kehagias, Ath.",
title="A hidden Markov model segmentation procedure for hydrological and environmental time series",
journal="Stochastic Environmental Research and Risk Assessment",
year="2004",
volume="18",
number="2",
pages="117--130",
abstract="In this paper we present a procedure for the segmentation of hydrological and enviromental time series. We consider the segmentation problem from a purely computational point of view which involves the minimization of Hubert's segmentation cost; in addition this least squares segmentation is equivalent to Maximum Likelihood segmentation. Our segmentation procedure maximizes Likelihood and minimizes Hubert's least squares criterion using a hidden Markov model (HMM) segmentation algorithm. This algorithm is guaranteed to achieve a local maximum of the Likelihood. We evaluate the segmentation procedure with numerical experiments which involve artificial, temperature and river discharge time series. In all experiments, the procedure actually achieves the global minimum of the Likelihood; furthermore execution time is only a few seconds, even for time series with over a thousand terms.",
issn="1436-3259",
doi="10.1007/s00477-003-0145-5",
url="http://dx.doi.org/10.1007/s00477-003-0145-5"
}

@article{fast_estimation_of_posterior_probabilities_in_change-point_analysis_through_a_constrained_hidden_markov_model,
    title = "Fast estimation of posterior probabilities in change-point analysis through a constrained hidden Markov model ",
    journal = "Computational Statistics and Data Analysis ",
    volume = "68",
    number = "",
    pages = "129 - 140",
    year = "2013",
    note = "",
    issn = "0167-9473",
    doi = "http://dx.doi.org/10.1016/j.csda.2013.06.020",
    url = "http://www.sciencedirect.com/science/article/pii/S0167947313002326",
    author = "The Minh Luong and Yves Rozenholc and Gregory Nuel",
    keywords = "Change-point estimation",
    keywords = "Segmentation",
    keywords = "Posterior distribution of change-points",
    keywords = "Constrained hidden Markov model",
    keywords = "Forwardâ€“backward algorithm",
    keywords = "Fast computation "
}

@inproceedings{inertial_hidden_markov_models_modeling_change_in_multivariate_time_series,
 author = {Monta\~{n}ez, George D. and Amizadeh, Saeed and Laptev, Nikolay},
 title = {Inertial Hidden Markov Models: Modeling Change in Multivariate Time Series},
 booktitle = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence},
 series = {AAAI'15},
 year = {2015},
 isbn = {0-262-51129-0},
 location = {Austin, Texas},
 pages = {1819--1825},
 numpages = {7},
 url = {http://dl.acm.org/citation.cfm?id=2886521.2886573},
 acmid = {2886573},
 publisher = {AAAI Press},
}

@article{bayesian_online_changepoint_detection,
  title={Bayesian online changepoint detection},
  author={Adams, Ryan Prescott and MacKay, David JC},
  journal={arXiv preprint arXiv:0710.3742},
  year={2007}
} 

@article{exact_and_efficient_bayesian_inference_for_multiple_changepoint_problems,
  author    = {Paul Fearnhead},
  title     = {Exact and efficient Bayesian inference for multiple changepoint problems},
  journal   = {Statistics and Computing},
  volume    = {16},
  number    = {2},
  pages     = {203--213},
  year      = {2006},
  url       = {http://dx.doi.org/10.1007/s11222-006-8450-8},
  doi       = {10.1007/s11222-006-8450-8},
  timestamp = {Mon, 16 Apr 2007 09:06:01 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/sac/Fearnhead06},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Misc{hellinger_distance,
author={Wikipedia},
title="{Hellinger distance}",
note={\url{https://en.wikipedia.org/wiki/Hellinger_distance/}},
year={2016}
}

@inproceedings{a_preliminary_performance_measurement_study_of_residential_broadband_services_in_brazil,
 author = {Mendes, Diego Ximenes and Senges, Guilherme da Silva and Santos, Gustavo Henrique Alves dos and Mendon\c{c}a, Gabriel and Le\~{a}o, Rosa M.M. and Silva, Edmundo de Souza e},
 title = {A Preliminary Performance Measurement Study of Residential Broadband Services in Brazil},
 booktitle = {Proceedings of the 2016 Workshop on Fostering Latin-American Research in Data Communication Networks},
 series = {LANCOMM '16},
 year = {2016},
 isbn = {978-1-4503-4426-5},
 location = {Florianopolis, Brazil},
 pages = {16--18},
 numpages = {3},
 url = {http://doi.acm.org/2940116.2940135},
 doi = {2940116.2940135},
 acmid = {2940135},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Access Networks, Broadband networks, Network measurement},
} 

@article{leveraging_cloud_data_to_mitigate_user_experience_from_breaking_bad,
  title={Leveraging Cloud Data to Mitigate User Experience from" Breaking Bad"},
  author={James, Nicholas A and Kejariwal, Arun and Matteson, David S},
  journal={arXiv preprint arXiv:1411.7955},
  year={2014}
}

@article{change_point_detection_in_time_series_data_by_relative_density_ratio_estimation,
title = "Change-point detection in time-series data by relative density-ratio estimation ",
journal = "Neural Networks ",
volume = "43",
number = "",
pages = "72 - 83",
year = "2013",
note = "",
issn = "0893-6080",
doi = "http://dx.doi.org/10.1016/j.neunet.2013.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S0893608013000270",
author = "Song Liu and Makoto Yamada and Nigel Collier and Masashi Sugiyama",
keywords = "Change-point detection",
keywords = "Distribution comparison",
keywords = "Relative density-ratio estimation",
keywords = "Kernel methods",
keywords = "Time-series data "
}

@inproceedings{learning_sparse_penalties_for_change_point_detection_using_max_margin_interval_regression, 
    Publisher = {JMLR Workshop and Conference Proceedings}, 
    Title = {Learning Sparse Penalties for Change-point Detection using Max Margin Interval Regression}, 
    Url = {http://jmlr.org/proceedings/papers/v28/hocking13.pdf}, 
    Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML-13)}, 
    Author = {Toby Hocking and Guillem Rigaill and Jean-philippe Vert and Francis Bach}, 
    Month = may, 
    Volume = {28}, 
    Editor = {Sanjoy Dasgupta and David Mcallester}, 
    Year = {2013}, 
    Pages = {172-180}, 
    Abstract = { In segmentation models, the number of change-points is typically chosen using a penalized cost function. In this work, we propose to learn the penalty and its constants in databases of signals with weak change-point annotations. We propose a convex relaxation for the resulting interval regression problem, and solve it using accelerated proximal gradient methods. We show that this method achieves state-of-the-art change-point detection in a database of annotated DNA copy number profiles from neuroblastoma tumors.} 
   }
